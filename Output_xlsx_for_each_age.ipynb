{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from scripts import bookdatafunctions as bdf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = bdf.initBooksFromConllus('Conllus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = bdf.mapGroup2Age(corpus, \"ISBN_MAPS/ISBN2AGE.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9789511269830_7_3', '9789527471562_8_1', '9789523640580_7_1', '9789511413813_7_1', '9789513173487_5_1', '9789515245908_6_1', '9789527269312_8_1', '9789523413405_7_1', '9789520413620_5_1', '9789513196462_5_1', '9789511282884_8_3', '9789526352916_7_3', '9789515252760_6_1', '9789515248794_6_1', '9789511264774_5_1', '9789523561885_8_1', '9789527343951_8_1', '9789523703582_7_1', '9789511425045_7_1', '9789510421185_6_1', '9789510446621_7_1', '9789510427927_7_1', '9789511372813_7_1', '9789523560833_8_1', '9789520423407_5_1', '9789523641686_8_1', '9789527269350_8_1', '9789511388975_8_1', '9789527269862_8_1', '9789520419912_7_1', '9789511274100_5_1', '9789523416819_7_1', '9789510447659_5_1', '9789523415348_7_1', '9789524090254_8_1', '9789511313212_8_1', '9789515251213_6_1', '9789520408879_5_1', '9789523702240_8_1', '9789511467069_8_1', '9789523562295_7_1', '9789523562905_7_1', '9789515252227_6_1', '9789511282891_5_1', '9789511453130_12_1', '9789527412381_11_1', '9789511228387_9_1', '9789511467304_9_1', '9789510437780_9_1', '9789510487594_9_1', '9789520414412_10_1', '9789511304142_9_1', '9789515262110_9_1', '9789510437773_9_1', '9789511436881_9_1', '9789511322245_9_1', '9789510377178_10_1', '9789523563889_11_1', '9789511461289_12_1', '9789511458708_12_1', '9789520413224_10_1', '9789523564985_9_1', '9789510487570_9_1', '9789511456285_12_1', '9789515262097_12_1', '9789523643673_12_1', '9789511458104_12_1', '9789523551848_12_1', '9789510447451_9_1', '9789515245922_9_1', '9789511471332_9_1', '9789515259882_9_1', '9789520455620_9_1', '9789511349938_12_1', '9789523564473_12_1', '9789510443910_10_1', '9789527373088_9_1', '9789512350414_11_1', '9789523563315_10_1', '9789511402909_12_1', '9789515249906_9_1', '9789512367771_9_1', '9789511371687_12_1', '9789510499368_12_1', '9789520413798_10_1', '9789510442579_9_1', '9789515246707_9_1', '9789511394990_12_1', '9789511342991_12_1', '9789511425700_9_1', '9789520432027_9_1', '9789515262141_9_1', '9789520413811_10_1', '9789511404408_12_1', '9789527413340_9_1', '9789523561847_11_1', '9789511378990_12_1', '9789523563865_12_1', '9789515262691_9_1', '9789511436874_9_1', '9789510497029_9_1', '9789520425135_10_1', '9789511378969_12_1', '9789515248718_9_1', '9789511458722_12_1', '9789511350316_14_1', '9789523560772_14_1', '9789523564978_13_1', '9789511299929_15_3', '9789511458036_14_1', '9789510350843_13_3', '9789511252825_13_3', '9789511469834_14_1', '9789523563834_13_1', '9789511362623_14_1', '9789526309330_14_3', '9789526308616_13_3', '9789511477013_14_2', '9789526308623_14_3', '9789511411369_14_1', '9789511457268_14_1', '9789523563841_14_1', '9789526310053_15_3', '9789523564947_13_1', '9789523562806_13_1', '9789511456322_13_1', '9789511307143_14_3', '9789527446171_14_1', '9789523561809_13_1', '9789511326267_14_1', '9789511307310_15_3', '9789526308630_15_3', '9789511449669_14_1', '9789523564954_13_1']\n"
     ]
    }
   ],
   "source": [
    "#Sort the books so that we get groupings by age group\n",
    "key1 = []\n",
    "key2 = []\n",
    "key3 = []\n",
    "for key in corpus.keys():\n",
    "    age = int(bdf.findAgeFromID(key))\n",
    "    if age<=8:\n",
    "        key1.append(key)\n",
    "    elif 8<age<13:\n",
    "        key2.append(key)\n",
    "    else:\n",
    "        key3.append(key)\n",
    "sorted_keys = key1+key2+key3\n",
    "\n",
    "print(sorted_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9789511453130_12_1', '9789527412381_11_1', '9789511228387_9_1', '9789511269830_7_3', '9789527471562_8_1', '9789511467304_9_1', '9789510437780_9_1', '9789523640580_7_1', '9789511350316_14_1', '9789523560772_14_1', '9789510487594_9_1', '9789520414412_10_1', '9789523564978_13_1', '9789511413813_7_1', '9789511304142_9_1', '9789513173487_5_1', '9789515262110_9_1', '9789510437773_9_1', '9789511436881_9_1', '9789511299929_15_3', '9789515245908_6_1', '9789511322245_9_1', '9789511458036_14_1', '9789510377178_10_1', '9789523563889_11_1', '9789527269312_8_1', '9789510350843_13_3', '9789511461289_12_1', '9789511458708_12_1', '9789520413224_10_1', '9789523413405_7_1', '9789523564985_9_1', '9789510487570_9_1', '9789511456285_12_1', '9789515262097_12_1', '9789511252825_13_3', '9789520413620_5_1', '9789513196462_5_1', '9789511469834_14_1', '9789523643673_12_1', '9789511282884_8_3', '9789526352916_7_3', '9789515252760_6_1', '9789515248794_6_1', '9789511264774_5_1', '9789523561885_8_1', '9789523563834_13_1', '9789511458104_12_1', '9789523551848_12_1', '9789510447451_9_1', '9789511362623_14_1', '9789515245922_9_1', '9789511471332_9_1', '9789527343951_8_1', '9789523703582_7_1', '9789511425045_7_1', '9789510421185_6_1', '9789515259882_9_1', '9789510446621_7_1', '9789520455620_9_1', '9789526309330_14_3', '9789511349938_12_1', '9789526308616_13_3', '9789511477013_14_2', '9789526308623_14_3', '9789523564473_12_1', '9789510427927_7_1', '9789511411369_14_1', '9789511372813_7_1', '9789510443910_10_1', '9789523560833_8_1', '9789520423407_5_1', '9789527373088_9_1', '9789512350414_11_1', '9789523641686_8_1', '9789511457268_14_1', '9789523563315_10_1', '9789527269350_8_1', '9789511402909_12_1', '9789515249906_9_1', '9789523563841_14_1', '9789512367771_9_1', '9789526310053_15_3', '9789523564947_13_1', '9789511388975_8_1', '9789511371687_12_1', '9789510499368_12_1', '9789523562806_13_1', '9789527269862_8_1', '9789511456322_13_1', '9789520419912_7_1', '9789511307143_14_3', '9789520413798_10_1', '9789511274100_5_1', '9789527446171_14_1', '9789523416819_7_1', '9789510442579_9_1', '9789510447659_5_1', '9789515246707_9_1', '9789511394990_12_1', '9789511342991_12_1', '9789523415348_7_1', '9789524090254_8_1', '9789511313212_8_1', '9789511425700_9_1', '9789515251213_6_1', '9789520432027_9_1', '9789515262141_9_1', '9789520413811_10_1', '9789511404408_12_1', '9789520408879_5_1', '9789523561809_13_1', '9789527413340_9_1', '9789523702240_8_1', '9789523561847_11_1', '9789511467069_8_1', '9789523562295_7_1', '9789511326267_14_1', '9789523562905_7_1', '9789511378990_12_1', '9789523563865_12_1', '9789515262691_9_1', '9789511436874_9_1', '9789515252227_6_1', '9789510497029_9_1', '9789511307310_15_3', '9789520425135_10_1', '9789526308630_15_3', '9789511378969_12_1', '9789515248718_9_1', '9789511458722_12_1', '9789511282891_5_1', '9789511449669_14_1', '9789523564954_13_1']\n"
     ]
    }
   ],
   "source": [
    "sorted_keys = list(corpus.keys())\n",
    "print(sorted_keys)\n",
    "sorted_keys.sort(key=lambda x:int(bdf.findAgeFromID(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9789513173487_5_1', '9789520413620_5_1', '9789513196462_5_1', '9789511264774_5_1', '9789520423407_5_1', '9789511274100_5_1', '9789510447659_5_1', '9789520408879_5_1', '9789511282891_5_1', '9789515245908_6_1', '9789515252760_6_1', '9789515248794_6_1', '9789510421185_6_1', '9789515251213_6_1', '9789515252227_6_1', '9789511269830_7_3', '9789523640580_7_1', '9789511413813_7_1', '9789523413405_7_1', '9789526352916_7_3', '9789523703582_7_1', '9789511425045_7_1', '9789510446621_7_1', '9789510427927_7_1', '9789511372813_7_1', '9789520419912_7_1', '9789523416819_7_1', '9789523415348_7_1', '9789523562295_7_1', '9789523562905_7_1', '9789527471562_8_1', '9789527269312_8_1', '9789511282884_8_3', '9789523561885_8_1', '9789527343951_8_1', '9789523560833_8_1', '9789523641686_8_1', '9789527269350_8_1', '9789511388975_8_1', '9789527269862_8_1', '9789524090254_8_1', '9789511313212_8_1', '9789523702240_8_1', '9789511467069_8_1', '9789511228387_9_1', '9789511467304_9_1', '9789510437780_9_1', '9789510487594_9_1', '9789511304142_9_1', '9789515262110_9_1', '9789510437773_9_1', '9789511436881_9_1', '9789511322245_9_1', '9789523564985_9_1', '9789510487570_9_1', '9789510447451_9_1', '9789515245922_9_1', '9789511471332_9_1', '9789515259882_9_1', '9789520455620_9_1', '9789527373088_9_1', '9789515249906_9_1', '9789512367771_9_1', '9789510442579_9_1', '9789515246707_9_1', '9789511425700_9_1', '9789520432027_9_1', '9789515262141_9_1', '9789527413340_9_1', '9789515262691_9_1', '9789511436874_9_1', '9789510497029_9_1', '9789515248718_9_1', '9789520414412_10_1', '9789510377178_10_1', '9789520413224_10_1', '9789510443910_10_1', '9789523563315_10_1', '9789520413798_10_1', '9789520413811_10_1', '9789520425135_10_1', '9789527412381_11_1', '9789523563889_11_1', '9789512350414_11_1', '9789523561847_11_1', '9789511453130_12_1', '9789511461289_12_1', '9789511458708_12_1', '9789511456285_12_1', '9789515262097_12_1', '9789523643673_12_1', '9789511458104_12_1', '9789523551848_12_1', '9789511349938_12_1', '9789523564473_12_1', '9789511402909_12_1', '9789511371687_12_1', '9789510499368_12_1', '9789511394990_12_1', '9789511342991_12_1', '9789511404408_12_1', '9789511378990_12_1', '9789523563865_12_1', '9789511378969_12_1', '9789511458722_12_1', '9789523564978_13_1', '9789510350843_13_3', '9789511252825_13_3', '9789523563834_13_1', '9789526308616_13_3', '9789523564947_13_1', '9789523562806_13_1', '9789511456322_13_1', '9789523561809_13_1', '9789523564954_13_1', '9789511350316_14_1', '9789523560772_14_1', '9789511458036_14_1', '9789511469834_14_1', '9789511362623_14_1', '9789526309330_14_3', '9789511477013_14_2', '9789526308623_14_3', '9789511411369_14_1', '9789511457268_14_1', '9789523563841_14_1', '9789511307143_14_3', '9789527446171_14_1', '9789511326267_14_1', '9789511449669_14_1', '9789511299929_15_3', '9789526310053_15_3', '9789511307310_15_3', '9789526308630_15_3']\n"
     ]
    }
   ],
   "source": [
    "print(sorted_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import bookdatafunctions as bdf\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Constants\n",
    "JSON_PATH = \"Parsed\"\n",
    "CONLLU_PATH = \"Conllus\"\n",
    "ISBN2AGE_PATH = \"ISBN_MAPS/ISBN2AGE.xlsx\"\n",
    "\n",
    "\n",
    "\n",
    "#books = bdf.initBooksFromJsons(JSON_PATH)\n",
    "\n",
    "#Move to working with just sentence data\n",
    "#Whole corpus\n",
    "sentences = bdf.mapGroup2Age(bdf.cleanWordBeginnings(bdf.cleanLemmas(bdf.initBooksFromConllus(CONLLU_PATH))), ISBN2AGE_PATH)\n",
    "\n",
    "ages = bdf.getAvailableAges(sentences)\n",
    "\n",
    "#Subcorpora based on the target age groups\n",
    "sub_sentences = []\n",
    "for i in ages:\n",
    "    sub_sentences.append(bdf.cleanWordBeginnings(bdf.cleanLemmas(bdf.getDistinctSubCorp(sentences, i))))\n",
    "\n",
    "#Versions of sentences for more meaningful data\n",
    "sub_sentences_no_punct = []\n",
    "for i in range(len(ages)):\n",
    "    sub_sentences_no_punct.append(bdf.cleanWordBeginnings(bdf.cleanLemmas(sub_sentences[i])))\n",
    "sentences_no_punct = bdf.cleanWordBeginnings(sentences)\n",
    "\n",
    "#Count lemma frequencies\n",
    "sub_lemma_freqs = []\n",
    "for i in range(len(ages)):\n",
    "    sub_lemma_freqs.append(bdf.getLemmaFrequencies(sub_sentences[i]))\n",
    "\n",
    "lemma_freqs = bdf.getLemmaFrequencies(sentences)\n",
    "\n",
    "#Count word frequencies\n",
    "sub_word_freqs = []\n",
    "for i in range(len(ages)):\n",
    "    sub_word_freqs.append(bdf.getWordFrequencies(sub_sentences[i]))\n",
    "\n",
    "word_freqs = bdf.getWordFrequencies(sentences)\n",
    "\n",
    "#Just for interest's sake, info on how many tokens (non-punct) are in each book\n",
    "\n",
    "sub_word_amounts = []\n",
    "for i in range(len(ages)):\n",
    "    sub_word_amounts.append(bdf.getTokenAmounts(sub_sentences[i]))\n",
    "\n",
    "word_amounts = bdf.getTokenAmounts(sentences)\n",
    "\n",
    "#Count the average uniq lemma lengths\n",
    "sub_avg_uniq_lemma_lens = []\n",
    "for i in range(len(ages)):\n",
    "    sub_avg_uniq_lemma_lens.append(bdf.getAvgLen(sub_lemma_freqs[i], 'lemma'))\n",
    "avg_uniq_lemma_lens = bdf.getAvgLen(lemma_freqs, 'lemma')\n",
    "#print(avg_uniq_lemma_lens)\n",
    "\n",
    "#Count the average uniq word lengths\n",
    "sub_avg_uniq_word_lens = []\n",
    "for i in range(len(ages)):\n",
    "    sub_avg_uniq_word_lens.append(bdf.getAvgLen(sub_word_freqs[i], 'text'))\n",
    "avg_uniq_word_lens = bdf.getAvgLen(word_freqs, 'text')\n",
    "#print(avg_uniq_word_lens)\n",
    "\n",
    "#Count the average lemma lengths\n",
    "sub_avg_lemma_lens = []\n",
    "for i in range(len(ages)):\n",
    "    sub_avg_lemma_lens.append(bdf.getAvgLen(sub_sentences_no_punct[i], 'lemma'))\n",
    "avg_lemma_lens = bdf.getAvgLen(sentences_no_punct, 'lemma')\n",
    "#print(avg_lemma_lens)\n",
    "\n",
    "#Count the average word lengths\n",
    "sub_avg_word_lens = []\n",
    "for i in range(len(ages)):\n",
    "    sub_avg_word_lens.append(bdf.getAvgLen(sub_sentences_no_punct[i], 'text'))\n",
    "avg_word_lens = bdf.getAvgLen(sentences_no_punct, 'text')\n",
    "#print(avg_word_lens)\n",
    "\n",
    "\n",
    "#Combining results into dfs\n",
    "avg_uniq_lens_dfs = []\n",
    "for i in range(len(ages)):\n",
    "    avg_uniq_lens_dfs.append(pd.DataFrame.from_dict([sub_avg_uniq_lemma_lens[i], sub_avg_uniq_word_lens[i]]).transpose().rename(columns={0: 'Unique lemmas avg length', 1: 'Unique words avg length'}))\n",
    "avg_uniq_lens_df = pd.DataFrame.from_dict([avg_uniq_lemma_lens, avg_uniq_word_lens]).transpose().rename(columns={0: 'Unique lemmas avg length', 1: 'Unique words avg length'})\n",
    "\n",
    "\n",
    "\n",
    "avg_lens_dfs = []\n",
    "for i in range(len(ages)):\n",
    "    avg_lens_dfs.append(pd.DataFrame.from_dict([sub_avg_lemma_lens[i], sub_avg_word_lens[i]]).transpose().rename(columns={0: 'Unique lemmas avg length', 1: 'Unique words avg length'}))\n",
    "avg_lens_df = pd.DataFrame.from_dict([avg_lemma_lens, avg_word_lens]).transpose().rename(columns={0: 'Unique lemmas avg length', 1: 'Unique words avg length'})\n",
    "\n",
    "#Constants to be used in different measures\n",
    "\n",
    "#The length of the corpus in words (no PUNCT)\n",
    "sub_l = []\n",
    "for i in range(len(ages)):\n",
    "    sub_l.append(bdf.getL(sub_word_amounts[i]))\n",
    "l = sum(sub_l)\n",
    "#The length of the corpus in parts\n",
    "n = len(sentences.keys())\n",
    "#The percentages of the n corpus part sizes\n",
    "sub_s = []\n",
    "for i in range(len(ages)):\n",
    "    sub_s.append(bdf.getS(sub_word_amounts[i], sub_l[i]))\n",
    "s = bdf.getS(word_amounts, l)\n",
    "#The overall frequencies of words in corpus\n",
    "sub_f_words = []\n",
    "for i in range(len(ages)):\n",
    "    sub_f_words.append(bdf.combineFrequencies(sub_word_freqs[i]))\n",
    "f_words = bdf.combineFrequencies(word_freqs)\n",
    "#The overall frequencies of lemmas in corpus\n",
    "sub_f_lemmas = []\n",
    "for i in range(len(ages)):\n",
    "    sub_f_lemmas.append(bdf.combineFrequencies(sub_lemma_freqs[i]))\n",
    "f_lemmas = bdf.combineFrequencies(lemma_freqs)\n",
    "#The frequencies of words in each corpus part\n",
    "v_words = word_freqs\n",
    "#The frequencies of lemmas in each corpus part\n",
    "v_lemmas = lemma_freqs\n",
    " \n",
    "#Get POS frequencies\n",
    "\n",
    "#Count POS frequencies\n",
    "\n",
    "pos_freqs_per_book = bdf.getPOSFrequencies(sentences)\n",
    "\n",
    "sub_pos_freqs = []\n",
    "for i in ages:\n",
    "    sub_pos_freqs.append(bdf.combineFrequencies(bdf.getDistinctSubCorp(pos_freqs_per_book, i)))\n",
    "\n",
    "pos_freqs_corpus = bdf.combineFrequencies(pos_freqs_per_book)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DP calculations: 100%|██████████| 126999/126999 [01:44<00:00, 1219.00it/s]\n",
      "DP calculations: 100%|██████████| 21882/21882 [00:01<00:00, 11066.52it/s]\n",
      "DP calculations: 100%|██████████| 40520/40520 [00:07<00:00, 5708.76it/s]\n",
      "DP calculations: 100%|██████████| 12030/12030 [00:00<00:00, 26163.16it/s]\n",
      "DP calculations: 100%|██████████| 38765/38765 [00:03<00:00, 10916.00it/s]\n",
      "DP calculations: 100%|██████████| 29810/29810 [00:01<00:00, 16130.53it/s]\n",
      "DP calculations: 100%|██████████| 16943/16943 [00:00<00:00, 17960.55it/s]\n",
      "DP calculations: 100%|██████████| 25952/25952 [00:02<00:00, 11768.44it/s]\n",
      "DP calculations: 100%|██████████| 4825/4825 [00:00<00:00, 30704.31it/s]\n",
      "DP calculations: 100%|██████████| 45947/45947 [00:05<00:00, 8085.70it/s]\n",
      "DP calculations: 100%|██████████| 21484/21484 [00:01<00:00, 20032.37it/s]\n",
      "DP calculations: 100%|██████████| 13235/13235 [00:00<00:00, 39024.58it/s]\n",
      "DP calculations: 100%|██████████| 346391/346391 [04:45<00:00, 1215.09it/s]\n",
      "DP calculations: 100%|██████████| 52646/52646 [00:04<00:00, 11065.55it/s]\n",
      "DP calculations: 100%|██████████| 110306/110306 [00:19<00:00, 5700.71it/s]\n",
      "DP calculations: 100%|██████████| 32198/32198 [00:01<00:00, 25652.84it/s]\n",
      "DP calculations: 100%|██████████| 97660/97660 [00:08<00:00, 10998.34it/s]\n",
      "DP calculations: 100%|██████████| 74546/74546 [00:04<00:00, 16235.32it/s]\n",
      "DP calculations: 100%|██████████| 37409/37409 [00:02<00:00, 17751.90it/s]\n",
      "DP calculations: 100%|██████████| 63631/63631 [00:05<00:00, 11837.85it/s]\n",
      "DP calculations: 100%|██████████| 9415/9415 [00:00<00:00, 33562.79it/s]\n",
      "DP calculations: 100%|██████████| 123976/123976 [00:15<00:00, 8221.11it/s]\n",
      "DP calculations: 100%|██████████| 53163/53163 [00:02<00:00, 18603.02it/s]\n",
      "DP calculations: 100%|██████████| 31638/31638 [00:00<00:00, 33751.21it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Whole corpus\n",
    "lemma_DP, lemma_DP_norm = bdf.getDP(v_lemmas, f_lemmas, s)\n",
    "#Sub-corpora\n",
    "sub_lemma_dp = []\n",
    "for i in range(len(ages)):\n",
    "    sub_lemma_dp.append(bdf.getDP(sub_lemma_freqs[i], sub_f_lemmas[i], sub_s[i])[0])\n",
    "#Whole corpus\n",
    "word_DP, word_DP_norm = bdf.getDP(v_words, f_words, s)\n",
    "#Sub-corpora\n",
    "sub_word_dp = []\n",
    "for i in range(len(ages)):\n",
    "    sub_word_dp.append(bdf.getDP(sub_word_freqs[i], sub_f_words[i], sub_s[i])[0])\n",
    "\n",
    "#Getting CD\n",
    "\n",
    "#Whole corpus\n",
    "word_CD = bdf.getCD(v_words)\n",
    "#Sub-corpora\n",
    "sub_word_cd = []\n",
    "for i in range(len(ages)):\n",
    "    sub_word_cd.append(bdf.getCD(sub_word_freqs[i]))\n",
    "\n",
    "#Whole corpus\n",
    "lemma_CD = bdf.getCD(v_lemmas)\n",
    "#Sub-corpora\n",
    "sub_lemma_cd = []\n",
    "for i in range(len(ages)):\n",
    "    sub_lemma_cd.append(bdf.getCD(sub_lemma_freqs[i]))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "#Combine previously gathered data into neat dataframes\n",
    "\n",
    "lemma_data, word_data = bdf.combineSeriesForExcelWriter(f_lemmas, sentences, lemma_DP, lemma_CD, f_words, word_DP, word_CD)\n",
    "print(len(ages))\n",
    "print(len(sub_f_lemmas))\n",
    "print(len(sub_sentences))\n",
    "print(len(sub_lemma_dp))\n",
    "print(len(sub_lemma_cd))\n",
    "print(len(sub_f_words))\n",
    "print(len(sub_word_dp))\n",
    "print(len(sub_word_cd))\n",
    "sub_data = []\n",
    "for i in range(len(ages)):\n",
    "    sub_data.append(bdf.combineSeriesForExcelWriter(sub_f_lemmas[i], sub_sentences[i], sub_lemma_dp[i], sub_lemma_cd[i], sub_f_words[i], sub_word_dp[i], sub_word_cd[i]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write to excel-files\n",
    "bdf.writeDataToXlsx(\"Whole_corpus\", lemmas=lemma_data, words=word_data, pos_freqs=pos_freqs_corpus)\n",
    "for i in range(len(ages)):\n",
    "    bdf.writeDataToXlsx(\"Sub_corpus_\"+str(ages[i]), lemmas=sub_data[i][0], words=sub_data[i][1], pos_freqs=sub_pos_freqs[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
